{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import liesel.model as lsl\n",
        "import liesel.goose as gs\n",
        "import liesel.contrib.splines as splines\n",
        "import tensorflow_probability.substrates.jax as tfp\n",
        "tfd = tfp.distributions\n",
        "tfb = tfp.bijectors\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "1-s31xMS0Re1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from liesel.contrib.splines import equidistant_knots, basis_matrix\n",
        "import tensorflow_probability.substrates.jax.bijectors as tfb\n",
        "from liesel.distributions.mvn_degen import MultivariateNormalDegenerate\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "import jax.numpy as jnp"
      ],
      "metadata": {
        "id": "osdRon7ODNLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Data for task\n",
        "def generate_gaussian_data(n, seed, M=3, c_u=0.0):\n",
        "    \"\"\"\n",
        "    Generate synthetic Gaussian-distributed data with replicates and a response variable.\n",
        "\n",
        "    Args:\n",
        "        n (int): The number of samples.\n",
        "        M (int, optional): The number of replicates per sample. Default is 3.\n",
        "        c_u (float, optional): The covariance factor between replicates. Default is 0.0.\n",
        "        seed (int, optional): Random seed for reproducibility. Default is None.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (y, x, replicates, sigma_matrices) as JAX arrays.\n",
        "    \"\"\"\n",
        "\n",
        "    # Set random seed for reproducibility\n",
        "\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    # Sample values for true covariate\n",
        "    x = np.random.normal(loc=10, scale=5, size=n)\n",
        "\n",
        "    # Generate covariance matrices\n",
        "    def create_sigma_me(dim_sigma_me, c_u):\n",
        "        Sigma_me = np.zeros((dim_sigma_me, dim_sigma_me))\n",
        "        for i in range(dim_sigma_me):\n",
        "            for j in range(dim_sigma_me):\n",
        "                if i == j:\n",
        "                    Sigma_me[i, j] = 1\n",
        "                else:\n",
        "                    Sigma_me[i, j] = c_u\n",
        "        return Sigma_me\n",
        "\n",
        "    # Scale the Sigma_me matrices by individual variance factor\n",
        "    sigma_matrices = []\n",
        "    for i in range(n):\n",
        "        sigma_sq_ui = 1 if i < n // 2 else 2  # First half scaled by 1, second half by 2\n",
        "        Sigma_me = create_sigma_me(M, c_u)\n",
        "        scaled_matrix = sigma_sq_ui * Sigma_me\n",
        "        sigma_matrices.append(scaled_matrix)\n",
        "\n",
        "    sigma_matrices_array = jnp.array(np.stack(sigma_matrices))\n",
        "\n",
        "    # Create M replicates of true variable x\n",
        "    replicates = []\n",
        "    for i in range(n):\n",
        "        mean_vector = np.repeat(x[i], M)\n",
        "        Sigma_me = sigma_matrices[i]\n",
        "        samples = np.random.multivariate_normal(mean_vector, Sigma_me)\n",
        "        replicates.append(samples)\n",
        "\n",
        "    # Generate response variable y\n",
        "    variances = np.random.choice([0.3, 0.5], size=n)\n",
        "    y_true = np.sin(x)\n",
        "\n",
        "    y = np.random.normal(loc=np.sin(x), scale=np.sqrt(variances))\n",
        "\n",
        "    # Convert to JAX arrays before returning\n",
        "    x = jnp.array(x)\n",
        "    replicates = jnp.array(np.array(replicates))\n",
        "    y_noise = jnp.array(y)\n",
        "    sigma_matrices = jnp.array(np.stack(sigma_matrices))\n",
        "\n",
        "    return y_noise, x, replicates, sigma_matrices, y_true"
      ],
      "metadata": {
        "id": "rZvSxnVQBvUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(x, y, n_param_splines, sigma, x_tilde = None, sample_x = False):\n",
        "  if sample_x:\n",
        "    # Define hyperparameters for variance of x\n",
        "    a_x = lsl.Var.new_param(0.001, name = \"a_x\")\n",
        "    b_x = lsl.Var.new_param(0.001, name = \"b_x\")\n",
        "\n",
        "    # Define prior for tau2_x using an Inverse Gamma distribution\n",
        "    tau2_x_prior = lsl.Dist(tfd.InverseGamma, concentration = a_x, scale = b_x)\n",
        "    tau2_x = lsl.Var.new_param(10.0, distribution = tau2_x_prior, name = \"tau2_x\")\n",
        "\n",
        "    # Define hyperparameters for mu_x (mean of x)\n",
        "    location_mu_x_prior = lsl.Var.new_param(0.0, name = \"location_mu_x_prior\")\n",
        "    scale_mu_x_prior = lsl.Var.new_param(1000.0, name= \"scale_mu_x_prior\")\n",
        "\n",
        "    # Define prior for mu_x using a Normal distribution\n",
        "    mu_x_prior = lsl.Dist(tfd.Normal, loc = location_mu_x_prior, scale = scale_mu_x_prior)\n",
        "\n",
        "    # Define mu_x as a parameter with the prior distribution\n",
        "    mu_x= lsl.Var.new_param(0.0, distribution = mu_x_prior, name = \"mu_x\")\n",
        "\n",
        "    # Define prior distribution for x\n",
        "    x_prior_dist = lsl.Dist(tfd.Normal, loc = mu_x, scale = tau2_x)\n",
        "\n",
        "    # Estimate x using the mean of replicates and assign a prior distribution\n",
        "    x_estimated = lsl.Var.new_param(jnp.expand_dims(x_tilde.mean(axis=1), -1), # initial estimation is the mean of the replicates\n",
        "                                    distribution = x_prior_dist,\n",
        "                                    name=\"x_estimated\")\n",
        "\n",
        "    # Define likelihood model for measurement error\n",
        "    measurement_dist = lsl.Dist(\n",
        "      tfd.MultivariateNormalFullCovariance,\n",
        "      loc=x_estimated,\n",
        "      covariance_matrix= sigma\n",
        "      )\n",
        "\n",
        "  # Define x_tilde (observed replicates) as observed data in the probabilistic model\n",
        "    x_tilde_var = lsl.Var.new_obs(\n",
        "        value = x_tilde,\n",
        "        distribution=measurement_dist,\n",
        "        name=\"x_tilde\"\n",
        "    )\n",
        "    # Generate equidistant knots for spline basis functions based on the mean of replicates (x_tilde)\n",
        "    knots = equidistant_knots(jnp.expand_dims(x_tilde.mean(axis=1), -1), n_param=n_param_splines, order=3)\n",
        "\n",
        "    # Compute spline basis matrix for modeling the mean function\n",
        "    basis_matrix_var_mu = lsl.Var.new_calc(\n",
        "      lambda x: splines.basis_matrix(\n",
        "          x.squeeze(),\n",
        "          knots=knots,    # Use precomputed knots\n",
        "          order=3,        # Cubic spline basis\n",
        "          outer_ok=True),\n",
        "        x = x_estimated,\n",
        "        name=\"basis_matrix_mu\"\n",
        "        )\n",
        "\n",
        "    # Compute spline basis matrix for modeling the scale\n",
        "    basis_matrix_var_scale = lsl.Var.new_calc(\n",
        "      lambda x: splines.basis_matrix(\n",
        "          x.squeeze(),\n",
        "          knots=knots,\n",
        "          order=3,\n",
        "          outer_ok=True),\n",
        "        x = x_estimated,\n",
        "        name=\"basis_matrix_scale\"\n",
        "        )\n",
        "  else:\n",
        "    # Generate equidistant knots for spline basis functions based on the mean of replicates (x_tilde)\n",
        "    knots = equidistant_knots(jnp.expand_dims(x, -1), n_param=n_param_splines, order=3)\n",
        "\n",
        "    # Compute spline basis matrix for modeling the mean function\n",
        "    basis_matrix_var_mu = lsl.Var.new_calc(\n",
        "      lambda x: splines.basis_matrix(\n",
        "          x.squeeze(),\n",
        "          knots=knots,    # Use precomputed knots\n",
        "          order=3,        # Cubic spline basis\n",
        "          outer_ok=True),\n",
        "        x = x,\n",
        "        name=\"basis_matrix_mu\"\n",
        "        )\n",
        "\n",
        "    # Compute spline basis matrix for modeling the scale\n",
        "    basis_matrix_var_scale = lsl.Var.new_calc(\n",
        "      lambda x: splines.basis_matrix(\n",
        "          x.squeeze(),\n",
        "          knots=knots,\n",
        "          order=3,\n",
        "          outer_ok=True),\n",
        "        x = x,\n",
        "        name=\"basis_matrix_scale\"\n",
        "        )\n",
        "\n",
        "  # Define intercept parameters for the mean and scale functions in the spline model\n",
        "  b0_mu = lsl.Var.new_param(0.0, name=\"b0_mu\")\n",
        "  b0_scale = lsl.Var.new_param(0.0, name=\"b0_scale\")\n",
        "\n",
        "  # Define hyperparameters for the variance of the mean function\n",
        "  a_var_mu = lsl.Var(0.001, name = \"a_mu\")\n",
        "  b_var_mu = lsl.Var(0.001, name = \"b_mu\")\n",
        "\n",
        "  # Define hyperparameters for the variance of the scale function\n",
        "  a_var_scale = lsl.Var(0.001, name = \"a_scale\")\n",
        "  b_var_scale = lsl.Var(0.001, name = \"b_scale\")\n",
        "\n",
        "  # Define prior tau2_mu distributions using Inverse Gamma\n",
        "  prior_tau2_mu = lsl.Dist(tfd.InverseGamma, concentration=a_var_mu, scale=b_var_mu)\n",
        "  tau2_mu = lsl.Var.new_param(10.0, distribution = prior_tau2_mu, name= \"tau2_mu\")\n",
        "\n",
        "  # Define prior tau2_scale distributions using Inverse Gamma\n",
        "  prior_tau2_scale = lsl.Dist(tfd.InverseGamma, concentration = a_var_scale, scale = b_var_scale)\n",
        "  tau2_scale = lsl.Var.new_param(10.0, distribution = prior_tau2_scale, name= \"tau_scale\")\n",
        "\n",
        "  # Compute P-spline penalty matrix (2nd-order difference for smoothness)\n",
        "  penalty = splines.pspline_penalty(d=n_param_splines,diff=2)\n",
        "\n",
        "  # Define penalty matrices for scale and mean functions\n",
        "  penalty_scale = lsl.Var(penalty, name= \"penalty_scale\")\n",
        "  penalty_mu = lsl.Var(penalty, name= \"penalty_mu\")\n",
        "\n",
        "  # Compute eigenvalues of the penalty matrix\n",
        "  evals = jax.numpy.linalg.eigvalsh(penalty)\n",
        "\n",
        "  # Compute rank of the penalty matrix (number of positive eigenvalues)\n",
        "  rank_scale = lsl.Value(jnp.sum(evals > 0.0), _name= \"rank_scale\")\n",
        "  rank_mu = lsl.Value(jnp.sum(evals > 0.0), _name= \"rank_mu\")\n",
        "\n",
        "  # Compute log determinant of the penalty matrix (ignoring zero eigenvalues)\n",
        "  log_pdet = jnp.log(jnp.where(evals > 0.0, evals, 1.0)).sum()\n",
        "  log_pdet_mu = lsl.Value(log_pdet, _name= \"log_pdet_mu\")\n",
        "  log_pdet_scale = lsl.Value(log_pdet, _name= \"log_pdet_scale\")\n",
        "\n",
        "  # Define prior distribution for spline coefficients (scale function)\n",
        "  prior_coef_scale  = lsl.Dist(\n",
        "      MultivariateNormalDegenerate.from_penalty,\n",
        "      loc= jnp.zeros(shape=(n_param_splines,)),\n",
        "      var= tau2_scale,\n",
        "      pen= penalty_scale,\n",
        "      rank = rank_scale,\n",
        "      log_pdet=log_pdet_scale\n",
        "      )\n",
        "\n",
        "  # Initialize spline coefficients for scale function\n",
        "  start_value_scale = np.zeros(np.shape(penalty)[-1], np.float32)\n",
        "  coef_scale = lsl.Var.new_param(start_value_scale, distribution= prior_coef_scale, name= \"coef_scale\")\n",
        "\n",
        "  # Define prior distribution for spline coefficients (mean function)\n",
        "  prior_coef_mu  = lsl.Dist(\n",
        "      MultivariateNormalDegenerate.from_penalty,\n",
        "      loc= jnp.zeros(shape=(n_param_splines,)),\n",
        "      var=tau2_mu,\n",
        "      pen= penalty_mu,\n",
        "      rank = rank_mu,\n",
        "      log_pdet=log_pdet_mu\n",
        "      )\n",
        "\n",
        "  # Initialize spline coefficients for mean function\n",
        "  start_value_mu = np.zeros(np.shape(penalty)[-1], np.float32)\n",
        "  coef_mu = lsl.Var.new_param(start_value_mu, distribution= prior_coef_mu, name= \"coef_mu\")\n",
        "\n",
        "  def pred_fn(beta0, spline_coef, basis_matrix):\n",
        "    return beta0 + jnp.dot(basis_matrix, spline_coef)\n",
        "\n",
        "    # Compute the scale (standard deviation) of y using the spline model\n",
        "  scale_of_y = lsl.Var.new_calc(\n",
        "      pred_fn,\n",
        "      beta0=b0_scale,                       # Intercept for scale function\n",
        "      spline_coef=coef_scale,               # Spline coefficients for scale\n",
        "      basis_matrix=basis_matrix_var_scale,  # Basis matrix for scale\n",
        "      name=\"scale_of_y\"\n",
        "  )\n",
        "\n",
        "  # Transform scale_of_y to ensure positivity (exponential transformation)\n",
        "  scale_of_y_transformed = lsl.Var.new_calc(jnp.exp, scale_of_y, name = \"scale_of_y_transformed\")\n",
        "\n",
        "  # Compute the mean (mu) of y using the spline model\n",
        "  mu_of_y = lsl.Var.new_calc(\n",
        "      pred_fn,\n",
        "      beta0= b0_mu,\n",
        "      spline_coef = coef_mu,\n",
        "      basis_matrix = basis_matrix_var_mu,\n",
        "      name=\"mu_of_y\"\n",
        "  )\n",
        "\n",
        "  # Define the likelihood distribution of y (Normal with estimated mean and scale)\n",
        "  y_dist = lsl.Dist(\n",
        "      tfd.Normal,\n",
        "      loc=mu_of_y,\n",
        "      scale= scale_of_y_transformed\n",
        "    )\n",
        "\n",
        "  # Define y as an observed variable with the specified distribution\n",
        "  y_var = lsl.Var.new_obs(\n",
        "      value=y,\n",
        "      distribution=y_dist,\n",
        "      name=\"y\"\n",
        "  )\n",
        "\n",
        "  if sample_x:\n",
        "    return lsl.Model([y_var, x_tilde_var])\n",
        "\n",
        "  else:\n",
        "    return lsl.Model([y_var])\n"
      ],
      "metadata": {
        "id": "UenvTgDP06zF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def engine_builder(model, x_sample = False):\n",
        "\n",
        "  def transition_tau_mu(prng_key, model_state):\n",
        "    \"\"\"\n",
        "    Sample tau2_mu from its posterior distribution using Gibbs sampling.\n",
        "\n",
        "    Args:\n",
        "        prng_key: The random number generator key for sampling.\n",
        "        model_state: A dictionary containing the model parameters and state.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the sampled tau2_mu.\n",
        "    \"\"\"\n",
        "    # Extract relevant parameters from model state\n",
        "    pos = interface.extract_position(\n",
        "        position_keys=[\"a_mu\", \"b_mu\", \"rank_mu\", \"penalty_mu\", \"coef_mu\"],\n",
        "        model_state=model_state\n",
        "    )\n",
        "    # Extract values from position\n",
        "    a_prior = pos[\"a_mu\"]\n",
        "    b_prior = pos[\"b_mu\"]\n",
        "    rank = pos[\"rank_mu\"]\n",
        "    K = pos[\"penalty_mu\"]\n",
        "    beta = pos[\"coef_mu\"]\n",
        "\n",
        "    # Compute the Gibbs sampling parameters\n",
        "    a_gibbs = jnp.squeeze(a_prior + 0.5 * rank)\n",
        "    b_gibbs = jnp.squeeze(b_prior + 0.5 * (beta @ K @ beta))\n",
        "\n",
        "    # Draw a sample from the gamma distribution\n",
        "    draw = b_gibbs / jax.random.gamma(prng_key, a_gibbs)\n",
        "\n",
        "    return {\"tau2_mu\": draw}\n",
        "\n",
        "\n",
        "  def transition_tau_scale(prng_key, model_state):\n",
        "    \"\"\"\n",
        "    Sample tau_scale from its posterior distribution using Gibbs sampling.\n",
        "\n",
        "    Args:\n",
        "        prng_key: The random number generator key for sampling.\n",
        "        model_state: A dictionary containing the model parameters and state.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the sampled tau_scale.\n",
        "    \"\"\"\n",
        "    # Extract relevant parameters from model state\n",
        "    pos = interface.extract_position(\n",
        "        position_keys=[\"a_scale\", \"b_scale\", \"rank_scale\", \"penalty_scale\", \"coef_scale\"],\n",
        "        model_state=model_state\n",
        "    )\n",
        "    # Extract values from position\n",
        "    a_prior = pos[\"a_scale\"]\n",
        "    b_prior = pos[\"b_scale\"]\n",
        "    rank = pos[\"rank_scale\"]\n",
        "    K = pos[\"penalty_scale\"]\n",
        "    beta = pos[\"coef_scale\"]\n",
        "\n",
        "    # Compute the Gibbs sampling parameters\n",
        "    a_gibbs = jnp.squeeze(a_prior + 0.5 * rank)\n",
        "    b_gibbs = jnp.squeeze(b_prior + 0.5 * (beta @ K @ beta))\n",
        "\n",
        "    # Draw a sample from the gamma distribution\n",
        "    draw = b_gibbs / jax.random.gamma(prng_key, a_gibbs)\n",
        "\n",
        "    return {\"tau_scale\" : draw}\n",
        "\n",
        "  def transition_mu_x(prng_key, model_state):\n",
        "    \"\"\"\n",
        "    Sample mu_x from its posterior distribution conditioned on the data.\n",
        "\n",
        "    Args:\n",
        "        prng_key: The random number generator key for sampling.\n",
        "        model_state: A dictionary containing the model parameters and state.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the sampled mu_x.\n",
        "    \"\"\"\n",
        "    # Extract relevant parameters from model state\n",
        "    pos = interface.extract_position(\n",
        "        position_keys=[\"x_estimated\", \"tau2_mu\", \"tau2_x\", \"a_x\", \"b_x\"],\n",
        "        model_state=model_state\n",
        "    )\n",
        "    x = pos[\"x_estimated\"]\n",
        "    n = len(x)\n",
        "    tau2_mu = pos[\"tau2_mu\"]\n",
        "    tau2_x = pos[\"tau2_x\"]\n",
        "    a_x = pos[\"a_x\"]\n",
        "    b_x = pos[\"b_x\"]\n",
        "\n",
        "    # Compute the posterior mean and standard deviation for mu_x\n",
        "    normal_sample = jax.random.normal(prng_key, (1,))\n",
        "    mu_mean = (n * jnp.mean(x) * tau2_mu) / (n * tau2_mu + tau2_x)\n",
        "    mu_std = jnp.sqrt(tau2_x * tau2_mu / (n * tau2_mu + tau2_x))\n",
        "\n",
        "    # Sample mu_x from a normal distribution\n",
        "    mu_x = jnp.squeeze(mu_mean + mu_std * normal_sample)\n",
        "\n",
        "    return {\"mu_x\": mu_x}\n",
        "\n",
        "\n",
        "  def transition_tau2_x(prng_key, model_state):\n",
        "    \"\"\"\n",
        "    Sample tau2_x from its posterior distribution using the inverse gamma distribution.\n",
        "\n",
        "    Args:\n",
        "        prng_key: The random number generator key for sampling.\n",
        "        model_state: A dictionary containing the model parameters and state.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the sampled tau2_x.\n",
        "    \"\"\"\n",
        "    # Extract relevant parameters from model state\n",
        "    pos = interface.extract_position(\n",
        "        position_keys=[\"a_x\", \"b_x\", \"x_estimated\", \"mu_x\", \"b_x\"],\n",
        "        model_state=model_state\n",
        "    )\n",
        "    a_x = pos[\"a_x\"]\n",
        "    b_x = pos[\"b_x\"]\n",
        "    x = pos[\"x_estimated\"]\n",
        "    n = len(x)\n",
        "    mu_x = pos[\"mu_x\"]\n",
        "\n",
        "    # Compute the new alpha and beta for the inverse gamma distribution\n",
        "    alpha_new = a_x + n / 2\n",
        "    beta_new = b_x + ((x - mu_x)**2).sum() / 2\n",
        "\n",
        "    # Sample tau2_x from the inverse gamma distribution\n",
        "    tau2_x = jnp.squeeze(tfd.InverseGamma(concentration=alpha_new, scale=beta_new).sample(seed=prng_key))\n",
        "\n",
        "    return {\"tau2_x\" : tau2_x}\n",
        "\n",
        "\n",
        "  def x_proposal(key, model_state, step_size):\n",
        "    \"\"\"\n",
        "    Propose a new value for x using a Metropolis-Hastings proposal distribution.\n",
        "\n",
        "    Args:\n",
        "        key: The random number generator key for sampling.\n",
        "        model_state: A dictionary containing the model parameters and state.\n",
        "        step_size: A scaling factor for the proposal distribution.\n",
        "\n",
        "    Returns:\n",
        "        gs.MHProposal: A Metropolis-Hastings proposal object containing the proposed x values and the log correction.\n",
        "    \"\"\"\n",
        "    # Extract current values of x_estimated and x_tilde from model state\n",
        "    pos = interface.extract_position(\n",
        "        position_keys=[\"x_estimated\", \"x_tilde\"],\n",
        "        model_state=model_state\n",
        "    )\n",
        "    x_current = pos[\"x_estimated\"].squeeze()  # Turn from (n, 1) into (n,)\n",
        "    n, m = pos[\"x_tilde\"].shape\n",
        "\n",
        "    # Initialize the step size scaling factor and covariance matrix\n",
        "    g = 1.0\n",
        "    M = m\n",
        "    eye_matrices = jnp.eye(m, dtype=jnp.float32)\n",
        "\n",
        "    # Create a stack of identity matrices and draw normal samples\n",
        "    sigma = jnp.stack([eye_matrices for _ in range(n)])  # (n, m, m)\n",
        "    normal_samples = jax.random.normal(key, (n,))  # (n,)\n",
        "\n",
        "    # Compute the scale factor for the proposal\n",
        "    trace_values = jnp.trace(sigma, axis1=1, axis2=2)  # (n,)\n",
        "    scale_factor = (g * trace_values / (M**2))  # (n,)\n",
        "\n",
        "    # Propose new x values\n",
        "    x_proposed = x_current + scale_factor * normal_samples * step_size  # (n,)\n",
        "    pos = {\"x_estimated\": jnp.expand_dims(x_proposed, -1)}  # Turn back into (n, 1)\n",
        "\n",
        "    return gs.MHProposal(pos, log_correction=0.0)\n",
        "\n",
        "  #add kernels and return engine\n",
        "  interface = gs.LieselInterface(model)\n",
        "  eb_sample = gs.EngineBuilder(seed = 2 , num_chains=4)\n",
        "  eb_sample.set_model(gs.LieselInterface(model))\n",
        "  eb_sample.set_initial_values(model.state)\n",
        "\n",
        "  eb_sample.add_kernel(gs.IWLSKernel([\"coef_scale\"]))\n",
        "  eb_sample.add_kernel(gs.IWLSKernel([\"coef_mu\"]))\n",
        "  eb_sample.add_kernel(gs.GibbsKernel([\"tau2_mu\"], transition_tau_mu))\n",
        "  eb_sample.add_kernel(gs.GibbsKernel([\"tau_scale\"], transition_tau_scale))\n",
        "\n",
        "  if x_sample:\n",
        "    eb_sample.add_kernel(gs.GibbsKernel([\"mu_x\"], transition_mu_x))\n",
        "    eb_sample.add_kernel(gs.RWKernel([\"x_estimated\"]))\n",
        "    eb_sample.add_kernel(gs.GibbsKernel([\"tau2_x\"], transition_tau2_x))\n",
        "\n",
        "  eb_sample.set_duration(warmup_duration = 1000, posterior_duration = 5000, thinning_posterior=10)\n",
        "\n",
        "  eb_sample.positions_included = [\"mu_of_y\", \"scale_of_y_transformed\"]\n",
        "\n",
        "  engine = eb_sample.build()\n",
        "\n",
        "  return engine"
      ],
      "metadata": {
        "id": "b-R3OessmUht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_sampling(num_sim, n, M, c_u, n_knots, x_sampling=False, x_naive=False):\n",
        "    \"\"\"\n",
        "    Perform multiple simulations to test spline-based modeling on Gaussian data.\n",
        "\n",
        "    Parameters:\n",
        "    - num_sim: Integer, number of simulations to run.\n",
        "    - n: Integer, number of data points per simulation.\n",
        "    - M: Some model parameter (purpose depends on generate_gaussian_data).\n",
        "    - c_u: covariance parameter (used in generate_gaussian_data).\n",
        "    - n_knots: Integer, number of knots in the spline basis.\n",
        "    - x_sampling: Boolean, if True, enables sampling of x values.\n",
        "    - x_naive: Boolean, if True, uses the mean of x_tilde instead of actual x values.\n",
        "\n",
        "    Returns:\n",
        "    - results: Dictionary containing various computed quantities across simulations.\n",
        "    \"\"\"\n",
        "\n",
        "    np.random.seed(42)  # Set random seed for reproducibility\n",
        "\n",
        "    # Generate an array of random seeds for each simulation\n",
        "    seeds_array = np.random.randint(low=2, high=1000, size=num_sim)\n",
        "\n",
        "    # Initialize result storage for different computed parameters\n",
        "    mu_coef_results = np.zeros((n_knots, num_sim))  # Mean coefficients for mu\n",
        "    scale_coef_results = np.zeros((n_knots, num_sim))  # Mean coefficients for scale\n",
        "    mu_mean_results = np.zeros((n, num_sim))  # Mean of mu values\n",
        "    sigma_mean_results = np.zeros((n, num_sim))  # Mean of sigma values\n",
        "\n",
        "    tau2_mu_results = []  # List to store tau^2 for mu\n",
        "    tau_scale_results = []  # List to store tau scale values\n",
        "    x_values_generated = np.zeros((n, num_sim))  # Store generated x values\n",
        "\n",
        "    # If x_sampling is enabled, initialize additional result storage\n",
        "    if x_sampling:\n",
        "        x_values = np.zeros((n, num_sim))  # Store estimated x values\n",
        "        mu_x_results = []  # Store mean mu_x values\n",
        "        tau2_x_results = []  # Store tau^2_x values\n",
        "\n",
        "    # Loop over simulations\n",
        "    for i in range(num_sim):\n",
        "        # Generate Gaussian data with given parameters and seed\n",
        "        y, x, x_tilde, sigma, y_true = generate_gaussian_data(n=n, seed=seeds_array[i], M=M, c_u=c_u)\n",
        "\n",
        "        # If x_naive is True, use the mean of x_tilde as input to the model\n",
        "        if x_naive:\n",
        "            model = create_model(\n",
        "                x=jnp.expand_dims(x_tilde.mean(axis=1), -1),\n",
        "                y=y,\n",
        "                sigma=sigma,\n",
        "                n_param_splines=n_knots,\n",
        "                sample_x=x_sampling\n",
        "            )\n",
        "            x_values_generated[:, i] = x_tilde.mean(axis=1)  # Store mean x_tilde values\n",
        "        else:\n",
        "            # Otherwise, use actual x values\n",
        "            model = create_model(\n",
        "                x=x,\n",
        "                y=y,\n",
        "                sigma=sigma,\n",
        "                n_param_splines=n_knots,\n",
        "                x_tilde=x_tilde,\n",
        "                sample_x=x_sampling\n",
        "            )\n",
        "            x_values_generated[:, i] = x_tilde.mean(axis=1)  # Store mean x_tilde values\n",
        "\n",
        "        # Build engine and run sampling\n",
        "        engine = engine_builder(model, x_sample=x_sampling)\n",
        "        engine.sample_all_epochs()\n",
        "\n",
        "        # Extract results from the engine\n",
        "        results = engine.get_results()\n",
        "        samples = results.get_posterior_samples()\n",
        "        summary = gs.Summary(results)\n",
        "\n",
        "        # Store spline coefficient results\n",
        "        mu_coef_results[:, i] = summary.quantities[\"mean\"][\"coef_mu\"]\n",
        "        scale_coef_results[:, i] = summary.quantities[\"mean\"][\"coef_scale\"]\n",
        "\n",
        "        # Store posterior mean estimates\n",
        "        mu_mean_results[:, i] = samples[\"mu_of_y\"].mean(axis=(0, 1))\n",
        "        sigma_mean_results[:, i] = samples[\"scale_of_y_transformed\"].mean(axis=(0, 1))\n",
        "\n",
        "        # Store tau2_mu and tau_scale results\n",
        "        tau2_mu_results.append(summary.quantities[\"mean\"][\"tau2_mu\"])\n",
        "        tau_scale_results.append(summary.quantities[\"mean\"][\"tau_scale\"])\n",
        "\n",
        "        # If x_sampling is enabled, store additional results\n",
        "        if x_sampling:\n",
        "            mu_x_results.append(summary.quantities[\"mean\"][\"mu_x\"])\n",
        "            tau2_x_results.append(summary.quantities[\"mean\"][\"tau2_x\"])\n",
        "            x_values[:, i] = summary.quantities[\"mean\"][\"x_estimated\"].squeeze()\n",
        "\n",
        "    # Compile results into a dictionary\n",
        "    results = {\n",
        "        \"mu_coef_results\": mu_coef_results,\n",
        "        \"scale_coef_results\": scale_coef_results,\n",
        "        \"tau2_mu_results\": tau2_mu_results,\n",
        "        \"tau_scale_results\": tau_scale_results,\n",
        "        \"mu_mean\": mu_mean_results,\n",
        "        \"sigma_mean\": sigma_mean_results,\n",
        "        \"x_values_generated\": x_values_generated\n",
        "    }\n",
        "\n",
        "    # If x_sampling is enabled, add x-related results\n",
        "    if x_sampling:\n",
        "        x_results = {\n",
        "            \"tau2_x_results\": tau2_x_results,\n",
        "            \"mu_x_results\": mu_x_results,\n",
        "            \"sampled_x_values\": x_values\n",
        "        }\n",
        "        results = results | x_results  # Merge dictionaries\n",
        "\n",
        "    return results  # Return the compiled results\n"
      ],
      "metadata": {
        "id": "K3t2GmUl2Ycf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}